<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>An Introduction to Gaussian Mixture Models | LabFab</title>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>An Introduction to Gaussian Mixture Models | LabFab</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="An Introduction to Gaussian Mixture Models" />
<meta name="author" content="stacknets" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Gaussian Mixture Models (GMMs) are powerful unsupervised learning tools used to model multimodal data distributions through a combination of multiple Gaussian distributions, applicable in various fields such as image segmentation, clustering, and audio feature extraction, leveraging the Expectation-Maximization (EM) algorithm for parameter estimation." />
<meta property="og:description" content="Gaussian Mixture Models (GMMs) are powerful unsupervised learning tools used to model multimodal data distributions through a combination of multiple Gaussian distributions, applicable in various fields such as image segmentation, clustering, and audio feature extraction, leveraging the Expectation-Maximization (EM) algorithm for parameter estimation." />
<link rel="canonical" href="http://localhost:4000/gaussian-processes/" />
<meta property="og:url" content="http://localhost:4000/gaussian-processes/" />
<meta property="og:site_name" content="LabFab" />
<meta property="og:image" content="http://localhost:4000/assets/images/dalle.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-01T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/assets/images/dalle.jpg" />
<meta property="twitter:title" content="An Introduction to Gaussian Mixture Models" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"stacknets"},"dateModified":"2024-05-01T00:00:00+02:00","datePublished":"2024-05-01T00:00:00+02:00","description":"Gaussian Mixture Models (GMMs) are powerful unsupervised learning tools used to model multimodal data distributions through a combination of multiple Gaussian distributions, applicable in various fields such as image segmentation, clustering, and audio feature extraction, leveraging the Expectation-Maximization (EM) algorithm for parameter estimation.","headline":"An Introduction to Gaussian Mixture Models","image":"http://localhost:4000/assets/images/dalle.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/gaussian-processes/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"stacknets"},"url":"http://localhost:4000/gaussian-processes/"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="LabFab">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>

                <!-- <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li> -->


                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">LabFab</h1>
    <p class="lead">
        Exploring math, physics, machine learning, and finance insights.
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=An Introduction to Gaussian Mixture Models&url=http://localhost:4000/gaussian-processes/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/gaussian-processes/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/gaussian-processes/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="/assets/images/avatar.png" alt="StackNets">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://labfab.io">StackNets</a><a target="_blank" href="https://twitter.com/capelfabio" class="btn follow">Follow</a>
                        <span class="author-description">I'm interested in machine learning, trading and running. I'm currently learning how to make the best focaccia possible and looking to collaborate on any project that makes me grow (though perhaps not in that order).</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">An Introduction to Gaussian Mixture Models</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid" src="/assets/images/dalle.jpg" alt="An Introduction to Gaussian Mixture Models">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#introduction-to-gmms">Introduction to GMMs</a>
    <ul>
      <li><a href="#example-of-gmm">Example of GMM</a></li>
    </ul>
  </li>
  <li><a href="#application-of-gmms">Application of GMMs</a></li>
  <li><a href="#mathematical-formulation-of-gmms">Mathematical Formulation of GMMs</a></li>
  <li><a href="#training-the-gmm-expectation-maximization-em-algorithm">Training the GMM: Expectation-Maximization (EM) algorithm</a>
    <ul>
      <li><a href="#steps-of-the-em-algorithm">Steps of the EM Algorithm</a></li>
    </ul>
  </li>
  <li><a href="#clustering-with-gmms">Clustering with GMMs</a></li>
  <li><a href="#challenges-and-considerations">Challenges and Considerations</a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <p>In this blog post, we will explore the concept of <strong>Gaussian Mixture Models</strong> (GMMs). These models are intuitive and widely applicable in various domains such as image segmentation, clustering, and generative modeling.</p>

<h2 id="introduction-to-gmms">Introduction to GMMs</h2>

<p>Gaussian Mixture Models are used to model an overall distribution through multiple Gaussian distributions. They are a powerful tool for capturing, estimating, and clustering parts of an overall distribution as locally Gaussian-distributed. GMMs are unsupervised models, meaning they do not need to know the specific Gaussian distribution a data point belongs to in advance.</p>

<h3 id="example-of-gmm">Example of GMM</h3>

<p>Here’s a simple example to illustrate GMMs:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># first gaussian
</span><span class="n">mean1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">standard_deviation</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">standard_deviation</span><span class="p">)</span>

<span class="c1"># second gaussian
</span><span class="n">mean2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.5</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">standard_deviation</span><span class="p">)</span>

<span class="c1"># third gaussian
</span><span class="n">mean3</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">y3</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">mean3</span><span class="p">,</span> <span class="n">standard_deviation</span><span class="p">)</span>

<span class="c1"># overall plotting
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y1</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y2</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y3</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y1</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="n">y2</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="n">y3</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Coordinates</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>This example shows three Gaussian distributions fitting an overall distribution, with the black line representing the combined distribution.</p>

<h2 id="application-of-gmms">Application of GMMs</h2>

<p>GMMs have numerous applications, including:</p>

<ul>
  <li>Image segmentation</li>
  <li>Multi-object tracking in videos</li>
  <li>Audio feature extraction</li>
</ul>

<p>They are particularly useful for multimodal distributions, where multiple peaks are present. These peaks can be modeled using multiple Gaussian distributions.</p>

<h2 id="mathematical-formulation-of-gmms">Mathematical Formulation of GMMs</h2>

<p>To represent GMMs mathematically, we need to understand three types of parameters:</p>

<ol>
  <li><strong>Mixture Weights</strong> (\(\phi\)): indicate the probability that a point belongs to a specific Gaussian component \(K\).</li>
  <li><strong>Means</strong> (\(\mu\)): the centers of each Gaussian component.</li>
  <li><strong>Covariances</strong> (\(\mathbf{\Sigma}_i\)): describe the spread and orientation of each Gaussian component.</li>
</ol>

<p>The probability density function for a GMM is given by:</p>

\[p(\mathbf{x}) = \sum_{i=1}^K \phi_i(\mathbf{x}) \mathcal{N}(\mathbf{x}|\mathbf{\mu}_i, \mathbf{\Sigma}_i)\]

<p>where \(\mathcal{N}(\mathbf{x}\vert\mathbf{\mu}_i, \mathbf{\Sigma}_i)\) is the multivariate Gaussian distribution.</p>

<h2 id="training-the-gmm-expectation-maximization-em-algorithm">Training the GMM: Expectation-Maximization (EM) algorithm</h2>

<p>The EM algorithm is used to find the maximum likelihood parameters of a GMM, especially when there are latent variables influencing the data distribution.</p>

<h3 id="steps-of-the-em-algorithm">Steps of the EM Algorithm</h3>

<ol>
  <li><strong>Expectation (E-step)</strong>: Estimate the latent variables.</li>
  <li><strong>Maximization (M-step)</strong>: Maximize the parameters based on the current estimates of the latent variables.</li>
</ol>

<p>In the particular case of GMMs, if one considers the maximum likelihood, we should maximize:</p>

\[\ln p(\mathbf{x}|\phi_i, \mathbf{\mu}, \mathbf{\Sigma}) = \sum_{n=1}^N \ln\left( \sum_{i=1}^K \phi_i(\mathbf{x}^{(n)}) \mathcal{N}(\mathbf{x}^{(n)}|\mathbf{\mu}_i, \mathbf{\Sigma}_i) \right)\]

<p>with respect to \(\theta = (\phi_i, \mathbf{\mu}_i, \mathbf{\Sigma}_i)\). However,
two problems arise by doing so: 1) we can have very high (arbitrarily large) likelihood when a
single Gaussian explains a point; 2) an unlimited number of solutions is acceptable up to
permutations. Instead, if we do introduce a latent variable \(z\), then one can consider that the
mixture model generates the data by first sampling from \(z\), and only then we sample the
observable data \(\mathbf{x}\) from a distribution that does depend on \(z\), meaning:</p>

\[p(z,\mathbf{x}) = p(z)p(\mathbf{x}|z).\]

<p>In mixture models, the <strong>latent variables are easily interpreted as being the different
components of the data distribution</strong>, i.e. \(z=c\) .</p>

<p>Let us try to optimize \(\ln p(\mathbf{x})\) for the set of parameters \(\theta\) by integrating
over the latent variable</p>

\[\begin{align}
\frac{d}{d\theta} \ln p(\mathbf{x}) &amp; = \frac{d}{d\theta} \ln \sum_{z} p(z, \mathbf{x})  \\
&amp; =  \frac{\frac{d}{d\theta} \sum_{z} p(z,\mathbf{x})}{\sum_{z'}p(z',\mathbf{x})}\\
&amp; = \sum_{z} p(z|\mathbf{x}) \frac{d}{d\theta} \ln p(z,\mathbf{x}) \\
&amp; = \mathbb{E}_{p(z|\mathbf{x})} \left[\frac{d}{d\theta} \ln p(z,\mathbf{x}) \right]. 
\end{align}\]

<p>This means that the derivative of the marginal log-probability \(p(\mathbf{x})\) is the expected
value of the derivative of the joint log-probability, with the expectation on the posterior
distribution. This formula is completely generic for any model with latent variables as we
did not introduce any specificities related to GMMs. We have not given the full details of
the derivation, but just keep in mind that we have used the known property:</p>

\[\frac{d}{d\theta} \ln A(\theta) = \frac{1}{A(\theta)} \frac{d}{d\theta} A(\theta).\]

<p>It is rather tempting to equalize the derivative to zero for the particular case of the GMMs.
Doing so, you end up with the optimum parameters that we are looking for. In particular, our
two previous steps of the EM algorithm become:</p>

<p><strong>E-Step</strong>:</p>

\[r_{ni} :=p(z_{n} = i | \mathbf{x}_n) = \frac{\phi_i \mathcal{N}(\mathbf{x}_n | \mathbf{\mu}_i,\mathbf{\Sigma}_i)}{\sum_{j=1}^K \phi_j \mathcal{N}(\mathbf{x}_n | \mathbf{\mu}_j,\mathbf{\Sigma}_j)}\]

<p><strong>M-Step</strong>:</p>

\[\phi_i = \frac{\sum_{n=1}^N r_{ni}}{\sum_{i=1}^K \sum_{n=1}^N r_{ni}}, \qquad \mathbf{\mu}_i = \frac{\sum_{n=1}^N  r_{ni}\mathbf{x}_n}{\sum_{n=1}^N r_{ni}}, \qquad \Sigma_{i} = \frac{\sum_{n=1}^N r_{ni} \left(\mathbf{x}_n -\mathbf{\mu}_i\right)\left(\mathbf{x}_n - \mathbf{\mu}_i\right)^\intercal}{\sum_{n=1}^N r_{ni}}\]

<p>These two steps define fully the EM algorithm for the GMMs with a random initialization of
the parameters \(\theta = \left\{\phi_i, \mathbf{\mu}_i, \mathbf{\Sigma}_i\right\}\).</p>

<h2 id="clustering-with-gmms">Clustering with GMMs</h2>

<p>…</p>

<h2 id="challenges-and-considerations">Challenges and Considerations</h2>

<p>GMMs require specifying the number of components beforehand. Model selection criteria such as Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) can help determine the optimal number of components. Additionally, the complexity of GMMs increases with the size of the dataset, particularly due to the covariance matrices. Simplifying assumptions, such as diagonal covariance matrices, can mitigate this issue.</p>

<p>In summary, Gaussian Mixture Models are a robust tool for modeling and clustering complex data distributions. Their ability to handle multimodal distributions makes them valuable in various practical applications.</p>

            </div>

            <!-- Rating -->
            
            <div class="rating mb-4 d-flex align-items-center">
                <strong class="mr-1">Rating:</strong> <div class="rating-holder">
<div class="c-rating c-rating--regular" data-rating-value="3.5">
  <button>1</button>
  <button>2</button>
  <button>3</button>
  <button>4</button>
  <button>5</button>
</div>
</div>
            </div>
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2024-05-01">01 May 2024</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/categories#machine-learning">machine learning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#unsupervised-learning">unsupervised learning</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="//diffusion-models/"> &laquo; Unlocking Creativity: Dalle 2 & Diffusion Models</a>
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'labfab'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

<script type="application/ld+json">
{
  "@context": "http://schema.org/",
  "@type": "Review",
  "itemReviewed": {
    "@type": "Thing",
    "name": "An Introduction to Gaussian Mixture Models"
  },
  "author": {
    "@type": "Person",
    "name": "StackNets"
  },
  "datePublished": "2024-05-01",
  "reviewRating": {
    "@type": "Rating",
    "ratingValue": "3.5",
    "bestRating": "5"
  }
}
</script>

</div>


<!-- Bottom Alert Bar
================================================== -->
<div class="alertbar">
	<div class="container text-center">
		<span><img src="/assets/images/logo.png" alt="LabFab" width="75" height="75"> &nbsp; Never miss a <b>story</b> from us, subscribe to our newsletter</span>
        <form action="https://wowthemes.us11.list-manage.com/subscribe/post?u=8aeb20a530e124561927d3bd8&amp;id=8c3d2d214b" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form>
	</div>
</div>

    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/categories#deep-learning">deep learning (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#artificial-intelligence">artificial intelligence (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#unsupervised-learning">unsupervised learning (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#machine-learning">machine learning (1)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2024 LabFab 
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//labfab.disqus.com/count.js"></script>


</body>
</html>
