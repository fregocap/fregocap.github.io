<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LabFab</title>
    <description>Exploring math, physics, machine learning, and finance insights.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 18 Apr 2025 01:06:56 +0200</pubDate>
    <lastBuildDate>Fri, 18 Apr 2025 01:06:56 +0200</lastBuildDate>
    <generator>Jekyll v4.3.3</generator>
    
      <item>
        <title>Bayesian Perspectives on Neural Networks: Uncertainty, Regularization, and Beyond</title>
        <description>&lt;p&gt;The incredible success of deep learning in recent years has transformed industries, 
scientific research, and everyday technologies. From computer vision to natural language processing, deep neural networks have demonstrated remarkable capabilities. However, these powerful models often lack a crucial feature: a principled approach to quantifying uncertainty in their predictions.&lt;/p&gt;

&lt;p&gt;Traditional neural networks typically output single point estimates, confidently predicting outcomes without expressing doubt. This can lead to overconfident decisions, particularly in high-stakes domaines like autonomous driving, medical diagnosis, or financial forecasting.&lt;/p&gt;

&lt;p&gt;Enter Bayesian neural networks (BNNs), which offer an elegant mathematical framework for addressing these limitations. By viewing neural networks through the lens of Bayesian probability theory, we gain tools for representing uncertainty, preventing overfitting, and understanding model behavior in a more principled way.&lt;/p&gt;

&lt;p&gt;In this deep dive, we’ll explore the theoretical foundations of Bayesian neural networks, examine their mathematical formuation, discuss practical implementation approaches, and consider their advantages and challenges. Whether you’re a machine learning practictioner, a statistics enthusiast, or a curious observer of AI developments, this exploration will give you a richer understanding of how probability theory can enhance neural network architectures.&lt;/p&gt;

&lt;h1 id=&quot;from-classical-to-bayesian-neural-networks&quot;&gt;From Classical to Bayesian Neural Networks&lt;/h1&gt;
&lt;h2 id=&quot;the-classical-neural-network-framework&quot;&gt;The Classical Neural Network Framework&lt;/h2&gt;

&lt;p&gt;Before delving into Bayesian approaches, let’s briefly review the classical neural network framework. A standard neural network can be represented as a function \(f_\theta(x)\) that maps inputs \(x\) to outputs \(y\) through a series of transformations parameterized by weights and biases collectively denoted as \(\theta\).&lt;/p&gt;

&lt;p&gt;The training process typically involves:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Defining a loss function \(L(y, f_\theta(x))\) that measures the discrepancy between predicted outputs and ground truth&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finding the optimal parameters \(\theta\) that minimize this loss: \(\theta = \arg\min_\theta \sum_{i=1}^{N} L(y_i, f_\theta(x_i))\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Using these fixed parameters for all future predictions&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This approach, known as maximum likelihood estimation (MLE) or its regularized variant maximum a posteriori (MAP) estimation, yeilds a single set of “best” parameters. While effective in many cases, this point estimate approach discards valuable information about parameter uncertainty.&lt;/p&gt;

&lt;h1 id=&quot;the-bayesian-paradigm-shift&quot;&gt;The Bayesian Paradigm Shift&lt;/h1&gt;

&lt;p&gt;The Bayesian approach fundamentally changes our perspective. Instead of searching for a single “best” set of parameters, we aim to capture the full distribution of plausible parameters given our observed data.&lt;/p&gt;

&lt;p&gt;Specifically, Bayesian neural networks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Start with a prior distribution over parameters \(p(\theta(x))\), representing our beliefs before seeing any data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Update this to a posterior distribution \(p(\theta(x) \| D)\) after observing dataset \(D={(x_1,y_1), (x_2, y_2),..., (x_N, y_N)}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make predictions by integrating over all possible parameter configurations, weighted by their posterior probability&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This shift from point estimates to probability distributions over parameters is the essence of the Bayesian perspective.&lt;/p&gt;

&lt;h1 id=&quot;mathematical-foundations-of-bayesian-neural-networks&quot;&gt;Mathematical Foundations of Bayesian Neural Networks&lt;/h1&gt;
&lt;h2 id=&quot;bayes-theorem-the-core-engine&quot;&gt;Bayes’ Theorem: The Core Engine&lt;/h2&gt;

&lt;p&gt;At the heart of Bayesian neural networks lies Bayes’ theorem:&lt;/p&gt;

\[p(\theta \| D) = \frac{p(D\|\theta)p(\theta)}{p(D)}\]

&lt;p&gt;Breaking this down:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(p(\theta \|D)\) is the posterior distribution over parameters given our observed data&lt;/li&gt;
  &lt;li&gt;\(p(D \| \theta)\) is the likelihood of observing our data given specific parameter values&lt;/li&gt;
  &lt;li&gt;$p(\theta)$ is our prior belief about parameter values before seeing any data&lt;/li&gt;
  &lt;li&gt;\(p(D)\) is the marginal likelihood or “evidence” (a normalizing constant)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For neural networks, the likelihood function typically reflects our assumptions about the data generation process. For regression problems, we might assume:&lt;/p&gt;

\[p(y \| x, \theta) = \mathcal{N}(y \|f_{\theta}(x), \sigma^2)\]

&lt;p&gt;Where \(\mathcal{N}\) denotes a Gaussian distribution with mean \(f_{\theta(x)}\) (the network’s prediction) and variance $\sigma^2$ (representing observation noise).&lt;/p&gt;

&lt;p&gt;For classification problems with $C$ classes, we might use:&lt;/p&gt;

\[p(y\| x, \theta) = \text{Categorical}(y | f_{\theta}(x), \sigma^2)\]

&lt;h2 id=&quot;prior-distributions-encoding-our-initial-beliefs&quot;&gt;Prior Distributions: Encoding Our Initial Beliefs&lt;/h2&gt;
&lt;p&gt;The choice of priod distribution $p(\theta)$ is crucial in Bayesian modeling, as it encodes our initial beliefs about parameter values before seeing any data. Common priors for neural network weights include:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gaussian priors&lt;/strong&gt;: $\theta \sim \mathcal{N}(0, \sigma^2_p)$, which encourage weights to remain small&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Laplace priors&lt;/strong&gt;: $\theta \sim \text{Laplace}(0, b)$, which encourage sparsity (many weights close to zero)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hierarchical priors: Where hyperparameters of the prior are themselves given distributions&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The connection between priors and regularization is profound. In fact, many common regularization techniques in deep learning can be interpreted as imposing specific Bayesian priors:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;L2 regularization (weight decay) corresponds to a Gaussian prior on weights&lt;/li&gt;
  &lt;li&gt;L1 regularization corresponds to a Laplace prior&lt;/li&gt;
  &lt;li&gt;Dropout can be interpreted as approximate Bayesian inference with specific prior structures&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;side-note proof&quot;&gt;
    &lt;h4&gt;Equivalence between Gaussian prior &amp;amp; L2 regularization&lt;/h4&gt;
    &lt;p&gt;Let us establish the equivalence between L2 regularization and imposing a Gaussian prior in a formal manner.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bayesian Framework&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;In Bayesian parameter estimation, we seek the posterior distribution of parameters $\theta$ given data $X$:&lt;/p&gt;

&lt;p&gt;$$P(\theta|X) = \frac{P(X|\theta)P(\theta)}{P(X)}$$&lt;/p&gt;

&lt;p&gt;Since $P(X)$ is constant with respect to $\theta$, we have:&lt;/p&gt;

&lt;p&gt;$$P(\theta|X) \propto P(X|\theta)P(\theta)$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maximum a Posteriori (MAP) Estimation&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;MAP estimation finds parameters that maximize the posterior:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\max_{\theta} P(\theta|X) = \arg\max_{\theta} P(X|\theta)P(\theta)$$&lt;/p&gt;

&lt;p&gt;Taking the logarithm (which preserves the argmax):&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\max_{\theta} [\log P(X|\theta) + \log P(\theta)]$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gaussian Prior&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Now we introduce a zero-mean Gaussian prior on the parameters:&lt;/p&gt;

&lt;p&gt;$$P(\theta) = \frac{1}{(2\pi\sigma^2)^{d/2}} \exp\left(-\frac{\|\theta\|^2}{2\sigma^2}\right)$$&lt;/p&gt;

&lt;p&gt;where $d$ is the dimensionality of $\theta$.&lt;/p&gt;

&lt;p&gt;Taking the logarithm:&lt;/p&gt;

&lt;p&gt;$$\log P(\theta) = -\frac{d}{2}\log(2\pi\sigma^2) - \frac{\|\theta\|^2}{2\sigma^2}$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MAP Estimation with Gaussian Prior&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Substituting the log-prior into our MAP objective:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\max_{\theta} \left[\log P(X|\theta) - \frac{d}{2}\log(2\pi\sigma^2) - \frac{\|\theta\|^2}{2\sigma^2}\right]$$&lt;/p&gt;

&lt;p&gt;Since the term $\frac{d}{2}\log(2\pi\sigma^2)$ is constant with respect to $\theta$, we can simplify:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\max_{\theta} \left[\log P(X|\theta) - \frac{\|\theta\|^2}{2\sigma^2}\right]$$&lt;/p&gt;

&lt;p&gt;Equivalently, by negating the objective:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\min_{\theta} \left[-\log P(X|\theta) + \frac{\|\theta\|^2}{2\sigma^2}\right]$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Connection to L2 Regularization&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Define the negative log-likelihood as our loss function $L(\theta;X) = -\log P(X|\theta)$. Then:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\min_{\theta} \left[L(\theta;X) + \frac{\|\theta\|^2}{2\sigma^2}\right]$$&lt;/p&gt;

&lt;p&gt;Setting $\lambda = \frac{1}{2\sigma^2}$, we get:&lt;/p&gt;

&lt;p&gt;$$\theta_{MAP} = \arg\min_{\theta} \left[L(\theta;X) + \lambda\|\theta\|^2\right]$$&lt;/p&gt;

&lt;p&gt;This is precisely the form of L2 regularization, where we minimize a loss function plus the squared L2 norm of the parameters, weighted by a regularization parameter $\lambda$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Therefore, L2 regularization in optimization is mathematically equivalent to imposing a zero-mean Gaussian prior on the parameters in a Bayesian framework, with the regularization strength $\lambda$ inversely related to the variance of the Gaussian prior as $\lambda = \frac{1}{2\sigma^2}$.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;posterior-predictive-distribution-integrating-over-uncertainty&quot;&gt;Posterior Predictive Distribution: Integrating Over Uncertainty&lt;/h2&gt;

&lt;p&gt;Perhaps the most powerful aspect of the Bayesian approach is how we make predictions. Rather than using a single set of parameters, we integrate over all possible parameters wieghted by their posterior probability:&lt;/p&gt;

\[p(y^*\|x^*, D) = \int p(y^*\|x^*, \theta)p(\theta\|D)d\theta\]

&lt;p&gt;This integration captures predictive uncertainty arising from both aleatoric uncertainty (inherent noise in the data) and epistemic uncertainty (our limited knowledge about true parameter values).&lt;/p&gt;

&lt;h1 id=&quot;epistemic-vs-aleatoric-uncertainty&quot;&gt;Epistemic vs Aleatoric Uncertainty&lt;/h1&gt;

&lt;p&gt;One of the greatest strengths of Bayesian neural networks is their ability to distinguish between different types of uncertainty:&lt;/p&gt;

&lt;h2 id=&quot;epistemic-uncertainty&quot;&gt;Epistemic Uncertainty&lt;/h2&gt;

&lt;p&gt;Epistemic uncertainty, also called model uncertainty, captures our ignorance about which model parmaeters best explain our observed data. This type of uncertainty:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Is higher in regions with sparse or no training data&lt;/li&gt;
  &lt;li&gt;Can be reduced by collecting more data&lt;/li&gt;
  &lt;li&gt;Is captured by the variance in predictions across different possible parameters values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mathematically, epistemic uncertainty is reflected in the spread of the posterior distribution $p(\theta|D)$. In regions far from training data, this posterior tends to revert toward the prior, increasing predictive uncertainty.&lt;/p&gt;

&lt;h2 id=&quot;aleatoric-uncertainty&quot;&gt;Aleatoric Uncertainty&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mountain_uncertainty.jpeg&quot; alt=&quot;Is the world about probability distributions? AI generated&quot; /&gt;
Aleatoric uncertainty captures inherent noise in the data generation process itself. This type of uncertainty:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cannot be reduced by collecting more data of the same quality&lt;/li&gt;
  &lt;li&gt;May vary across the input space (heteroscedastic noise)&lt;/li&gt;
  &lt;li&gt;Is typically modeled directly in the likelihood function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For regression problems, a common approach is to have the neural network predict both the mean and variance of the target distribution, allowing it to express higher uncertainty for intrinsically noisy data points.&lt;/p&gt;

&lt;h1 id=&quot;practical-approaches-to-bayesian-neural-networks&quot;&gt;Practical Approaches to Bayesian Neural Networks&lt;/h1&gt;

&lt;p&gt;While the theory of Bayesian neural networks is elegant, exact Bayesian inference is computationally intractable for modern deep learning architectures. This has led to the development of various approximation techniques:&lt;/p&gt;

&lt;h3 id=&quot;markov-chain-monte-carlo-mcmc-methods&quot;&gt;Markov Chain Monte Carlo (MCMC) Methods&lt;/h3&gt;

&lt;p&gt;MCMC methods approximate the posterior by generating samples. For neural networks, Hamiltonian Monte Carlo (HMC) and its variants like the No-U-Turn Sampler (NUTS) have shown promise. These methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Provide asymptotically exact samples from the posterior&lt;/li&gt;
  &lt;li&gt;Scale poorly with parameter dimension and dataset size&lt;/li&gt;
  &lt;li&gt;Work best for smaller networks or with specialized hardware&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;variational-inference&quot;&gt;Variational Inference&lt;/h2&gt;
&lt;p&gt;Variational inference approximates the true posterior $p(\theta |D)$ with a simpler distribution $q_{\phi}(\theta)$, parametrized by $\phi$. We then minimize the Kullback-Leibler divergence between these distributions:&lt;/p&gt;

\[\phi^* = \text{arg min}_{\phi} \text{KL}(q_{\phi}(\theta) \| p(\theta |D) )\]

&lt;p&gt;This is equivalent to maximizing the evidence lower bound (ELBO):&lt;/p&gt;

\[\mathcal{L}(\phi) = \mathbb{E}_{q_{\phi}(\theta)}\left[\log p(D|\theta) - \text{KL}(q_{\phi}(\theta) | p(\theta)) \right]\]

&lt;p&gt;Popular approaches include:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Mean-field variational inference&lt;/strong&gt;: Assumes independence between parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bayes by Backprop&lt;/strong&gt;: Backpropagates through the variational objective&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flipout&lt;/strong&gt;: Uses correlated weight perturbations for more efficient gradient estimation&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;monte-carlo-dropout&quot;&gt;Monte Carlo Dropout&lt;/h2&gt;

&lt;p&gt;Perhaps the most practical approach is Monte Carlo dropout, which interprets dropout (a common regularization technique) as approximate Bayesian inference. The procedure is remarkably simple:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Train a network with dropout as usual&lt;/li&gt;
  &lt;li&gt;At test time, keep dropout active&lt;/li&gt;
  &lt;li&gt;Run multiple forward passes with different dropout masks&lt;/li&gt;
  &lt;li&gt;Use the mean of these predictions as your predictino and their variance as a measure of uncertainty&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This approach requires minimal changes to existing architectures and training procedures, making it particularly appealing for practitioners.&lt;/p&gt;

&lt;h2 id=&quot;deep-ensembles&quot;&gt;Deep Ensembles&lt;/h2&gt;

&lt;p&gt;While not strictly Bayesian, deep ensembles (training multiple networks with different random initialization) provide a pragmatic alternative that captures many benefits of Bayesian inference:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Train $M$ independent neural networks with different random initializations&lt;/li&gt;
  &lt;li&gt;Use the mean of their predictions as the ensemble prediction&lt;/li&gt;
  &lt;li&gt;Use the variance across ensembles members as a measure of uncertainty&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Despite their simplicity, deep ensembles have demonstrated competitive or superior uncertainty quantification compared to more complex Bayesian approaches.&lt;/p&gt;

&lt;h1 id=&quot;applications-and-benefits-of-bayesian-neural-networks&quot;&gt;Applications and Benefits of Bayesian Neural Networks&lt;/h1&gt;
&lt;p&gt;The Bayesian approach to neural networks offers several advantages that make it particularly valuable in certain domains:&lt;/p&gt;

&lt;h2 id=&quot;active-learning-and-experimental-design&quot;&gt;Active Learning and Experimental Design&lt;/h2&gt;
&lt;p&gt;In active learning scenarios, an agent must decide which data points to collect labels for. Bayesian neural networks naturally suggest an acquisition strategy: select points with high epistemic uncertainty, where the model’s knowledge is lacking.&lt;/p&gt;

&lt;p&gt;This approach has proven effective in areas like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scientific experimentation, where collecting data is expensive&lt;/li&gt;
  &lt;li&gt;Medical imaging, where expert annotation time is limited&lt;/li&gt;
  &lt;li&gt;Robotics, where exploration must be balanced with exploitation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;outlier-and-adversarial-example-detection&quot;&gt;Outlier and Adversarial Example Detection&lt;/h2&gt;
&lt;p&gt;Bayesian neural networks typically assign high uncertainty to inputs that differ significantly from their training distribution. This property can be leveraged to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Detect outliers or anomalous inputs&lt;/li&gt;
  &lt;li&gt;Identify potential adversarial examples&lt;/li&gt;
  &lt;li&gt;Flag inputs where the model’s prediction should not be trusted&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;automatic-model-regularization&quot;&gt;Automatic Model Regularization&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/islands_uncertainty.jpeg&quot; alt=&quot;The islands of uncertainty - AI generated&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Bayesian formulation naturally prevents overfitting through:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Marginalization over parameters, which averages out spurious patterns&lt;/li&gt;
  &lt;li&gt;Prior distributions that encode useful inductive biases&lt;/li&gt;
  &lt;li&gt;Automatic complexity control via the “Bayesian Occam’s razor” effect&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;continual-learning&quot;&gt;Continual Learning&lt;/h2&gt;
&lt;p&gt;In continual learning scenarios, where models must adapt to new tasks without forgetting old ones, Bayesian approaches offer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Natural incorporation of previous knowledge via the posterior-to-prior mechanism&lt;/li&gt;
  &lt;li&gt;Resistance to catastrophic forgetting&lt;/li&gt;
  &lt;li&gt;Principled ways to balance old and new information&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;challenges-and-limitations&quot;&gt;Challenges and Limitations&lt;/h1&gt;

&lt;p&gt;Despite their theoretical appeal, Bayesian neural networks face several practical challenges:&lt;/p&gt;

&lt;h2 id=&quot;computational-complexity&quot;&gt;Computational Complexity&lt;/h2&gt;
&lt;p&gt;Exact Bayesian inference scales poorly with model size and dataset size. Even with approximaton methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training is typically slower than for standard neural networks&lt;/li&gt;
  &lt;li&gt;Memory requirements can be significantly higher&lt;/li&gt;
  &lt;li&gt;Prediciton requires multiple forward passes or sampling operations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;specification-of-meaningful-priors&quot;&gt;Specification of Meaningful Priors&lt;/h2&gt;

&lt;p&gt;Choosing appropriate priors for complex deep networks is challenging:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Conventional priors may not capture the complex dependencies between parameters&lt;/li&gt;
  &lt;li&gt;The impact of priors diminishes with large datasets&lt;/li&gt;
  &lt;li&gt;Layer-wise correlations and architectural inductive biases are difficult to encode&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;scalability-to-modern-architectures&quot;&gt;Scalability to Modern Architectures&lt;/h2&gt;

&lt;p&gt;Applying Bayesian principles to state-of-the-art architectures like transformers or large convolutional networks remains challenging due to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Memory limitations&lt;/li&gt;
  &lt;li&gt;Convergence issues with variational methods&lt;/li&gt;
  &lt;li&gt;Difficulties in amortizing inference across model components&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluation-metrics&quot;&gt;Evaluation Metrics&lt;/h2&gt;

&lt;p&gt;Evaluating Bayesian neural networks requires looking beyond accuracy to assess calibration and uncertainty quantification:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Proper scoring rules like log-likelihood or Brier score&lt;/li&gt;
  &lt;li&gt;Calibration metrics like expected calibration error&lt;/li&gt;
  &lt;li&gt;Selective prediction evaluations like retention curves&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;recent-advances-and-future-directions&quot;&gt;Recent Advances and Future Directions&lt;/h1&gt;

&lt;p&gt;The field of Bayesian deep learning continues to evolve rapidly. Recent advances include:&lt;/p&gt;

&lt;h2 id=&quot;implicit-variational-inference&quot;&gt;Implicit Variational Inference&lt;/h2&gt;

&lt;p&gt;Newer methods avoid explicitly specifying the form of the approximate posterior, instead learning it implicitly through generative models or normalizing flows.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-weight-averaging-swa-and-swa-gaussian-swag&quot;&gt;Stochastic Weight Averaging (SWA) and SWA-Gaussian (SWAG)&lt;/h2&gt;

&lt;p&gt;These methods approximate the posterior by fitting a Gaussian distribution to points along the optimization trajectory, offering a simple yet effective approach to uncertainty estimation.&lt;/p&gt;

&lt;h2 id=&quot;function-space-inference&quot;&gt;Function-Space Inference&lt;/h2&gt;

&lt;p&gt;Rather than reasoning about the posterior over weights, some approaches directly target the posterior over functions, which can be more interpretable and effective for uncertainty quantification.&lt;/p&gt;

&lt;h2 id=&quot;neural-network-architecture-search&quot;&gt;Neural Network Architecture Search&lt;/h2&gt;

&lt;p&gt;Combining Bayesian principles with neural architecture search allows for jointly optimizing model structure and parameter uncertainty.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Bayesian neural networks offer a principled framework for reasoning about uncertainty in deep learning models. By viewing neural networks through the lens of Bayesian probability theory, we gain powerful tools for understanding model behavior, preventing overfitting, and making robust predictions in the face of limited data.&lt;/p&gt;

&lt;p&gt;While practical challenges remain, especially around scalability and computational efficiency, the field is advancing rapidly. The growing recognition of uncertainty quantification’s importance in deploying AI systems safely and responsibly suggests that Bayesian approaches will continue to play a crucial role in the future of deep learning.&lt;/p&gt;

&lt;p&gt;Whether implemented through variational inference, Monte Carlo dropout, or ensemble methods, the core principles of Bayesian statistics provide valuable guidance for developing more robust, trustworthy, and interpretable neural networks. As computational techniques continue to improve, we can expect Bayesian methods to become increasingly practical for mainstream deep learning applications.&lt;/p&gt;

&lt;div class=&quot;references&quot;&gt;
    &lt;h2&gt;References&lt;/h2&gt;
    &lt;ol&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Weight Uncertainty in Neural Networks&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Blundell, C., Cornebise, J., Kavukcuoglu, K., &amp;amp; Wierstra, D.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;International Conference on Machine Learning (2015).&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/1505.05424&quot; class=&quot;reference-doi&quot;&gt;arXiv:1505.05424v2&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Gal, Y., &amp;amp; Ghahramani, Z.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;International Conference on Machine Learning (2016)&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/1506.02142&quot; class=&quot;reference-doi&quot;&gt;arXiv:1506.02142v6&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Variational Dropout and the Local Reparameterization Trick&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Kingma, D. P., Salimans, T., &amp;amp; Welling, M. &lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Advances in Neural Information Processing Systems. (2015)&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/1506.02557&quot; class=&quot;reference-doi&quot;&gt;arXiv:1506.02557v2&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Lakshminarayanan, B., Pritzel, A., &amp;amp; Blundell, C.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Advances in Neural Information Processing Systems (2017).&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/1612.01474&quot; class=&quot;reference-doi&quot;&gt;arXiv:1612.01474v3&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;A Practical Bayesian Framework for Backpropagation Networks&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;MacKay, D. J. &lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Neural Computation (1992)&lt;/span&gt;
            &lt;a href=&quot;https://core.ac.uk/download/pdf/216127203.pdf&quot; class=&quot;reference-doi&quot;&gt;4,448-472&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Bayesian Learning for Neural Networks&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Neal, R. M.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Springer Science &amp;amp; Business Media.&lt;/span&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Practical Variational Inference for Neural Networks.&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Graves, A.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Advances in Neural Information Processing Systems.(2011)&lt;/span&gt;
            &lt;a href=&quot;https://papers.nips.cc/paper_files/paper/2011/file/7eb3c8be3d411e8ebfab08eba5f49632-Paper.pdf&quot; class=&quot;reference-doi&quot;&gt;NIPS&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Kendall, A., &amp;amp; Gal, Y.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Advances in Neural Information Processing Systems (2017)&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/1703.04977&quot; class=&quot;reference-doi&quot;&gt;arXiv:1703.04977v2&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;Bayesian Deep Learning and a Probabilistic Perspective of Generalization&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Wilson, A. G., &amp;amp; Izmailov, P.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;Advances in Neural Information Processing Systems. (2020)&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/2002.08791&quot; class=&quot;reference-doi&quot;&gt;arXiv:2002.08791v4&lt;/a&gt;
        &lt;/li&gt;
        &lt;li&gt;
            &lt;span class=&quot;reference-title&quot;&gt;How Good is the Bayes Posterior in Deep Neural Networks Really?&lt;/span&gt;
            &lt;span class=&quot;reference-authors&quot;&gt;Wenzel, F., Roth, K., Veeling, B. S., Świątkowski, J., Tran, L., Mandt, S., ... &amp;amp; Nowozin, S.&lt;/span&gt;
            &lt;span class=&quot;reference-details&quot;&gt;International Conference on Machine Learning. (2020)&lt;/span&gt;
            &lt;a href=&quot;https://arxiv.org/pdf/2002.02405&quot; class=&quot;reference-doi&quot;&gt;arXiv:2002.02405v2&lt;/a&gt;
        &lt;/li&gt;        
    &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 16 Apr 2025 00:00:00 +0200</pubDate>
        <link>http://localhost:4000/bayesian-neural-net/</link>
        <guid isPermaLink="true">http://localhost:4000/bayesian-neural-net/</guid>
        
        <category>bayesian neural networks</category>
        
        <category>uncertainty quantification</category>
        
        <category>probabilistic modeling</category>
        
        <category>variational inference</category>
        
        <category>MCMC</category>
        
        <category>deep ensembles</category>
        
        <category>epistemic uncertainty</category>
        
        <category>aleatoric uncertainty</category>
        
        <category>TensorFlow Probability</category>
        
        
        <category>machine learning</category>
        
        <category>deep learning</category>
        
        <category>bayesian statistics</category>
        
      </item>
    
      <item>
        <title>Trend Following Strategies: Hidden Protection for Long-Term Investors</title>
        <description>&lt;p&gt;Last week I came across a fascinating research paper, “Tail Protection for Long Investors: Trend Convexity at Work” by researchers from Capital Fund Management. As someone who’s weathered multiple market cycles, I’ve always been intrigued by investment strategies that can protect portfolios during turbulent times. The 2008 financial crisis and the March 2020 COVID crash demonstrated just how quickly markets can unravel, leaving many investors scrambling for protection.&lt;/p&gt;

&lt;p&gt;Most long-term investors face a common dilemma: how to maintain exposure to market growth while protecting against significant downturns. Traditional approaches like diversification often fail during crises when correlations spike. Buying put options works but comes at a steep cost that erodes returns over time. This is where trend following strategies reveal their hidden superpower—&lt;strong&gt;convexity&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;what-makes-trend-following-special&quot;&gt;What Makes Trend Following Special?&lt;/h1&gt;

&lt;p&gt;Unlike typical hedge fund strategies that often disappoint during market crashes (showing negative convexity), trend following strategies have historically performed better during periods of high volatility. Look at the performance of Commodity Trading Advisors (CTAs) during the 2008 Lehman crisis—they delivered strong positive returns while markets collapsed.&lt;/p&gt;

&lt;p&gt;This distinctive behavior makes trend strategies a potentially valuable addition to long-only portfolios. But what drives this performance? The researchers explain it through a surprisingly elegant mathematical relationship. The performance of trend following can be understood as the difference between &lt;strong&gt;long-term variance&lt;/strong&gt; and &lt;strong&gt;short-term variance&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;the-mathematics-behind-the-magic&quot;&gt;The Mathematics Behind the Magic&lt;/h1&gt;
&lt;p&gt;For those who enjoy the technical details, here’s the core insight: If we define a simple trend strategy where the positino \(\Pi\) at time \(t\) is proportional to the price difference:&lt;/p&gt;

\[\Pi_t := \lambda A_t \left(S_t - S_{0}\right)\]

&lt;p&gt;where \(\lambda\) is a scaling factor and \(A_t\) is the capital engaged (set to 1 for simplicity). The profit and loss (PnL) from \(t-1\) to \(t\) becomes:&lt;/p&gt;

\[G_t:= \Pi_{t-1} D_t = \lambda D_t \sum_{t&apos;=1}^{t-1} D_{t&apos;}\]

&lt;p&gt;where \(D_t\)  is the price changes from \(t-1\) to \(t\). Aggregating this over \(T\) over \(T\) days and rearranging the sums:&lt;/p&gt;

\[G_t = \frac{\lambda}{2} \left(S_T - S_0 \right)^2 - \frac{\lambda}{2} \sum_{t=1}^{T} D_t^2\]

&lt;p&gt;This means the strategy’s average aggregated performance equals:&lt;/p&gt;

\[\left\langle \sum_{t=1}^{T}G_t \right\rangle = \frac{\lambda T}{2}\left(\sigma^2(T) - \sigma^2(1)\right)\]

&lt;p&gt;In plain English: trend following strategies swap &lt;strong&gt;short-term volatility&lt;/strong&gt; for &lt;strong&gt;long-term volatility&lt;/strong&gt;. When markets make large moves over extended periods, these strategies shine. This creates a natural convexity in the performance profile - the strategy performs increasingly better as market volatility increases.&lt;/p&gt;

&lt;p&gt;I’ve found this insight particularly valuable in my own investing. During calm markets, trend following often underperforms or generates modest returns. But when markets experience extended turbulence, these strategies can deliver outsized performance that helps offset losses in traditional investments.&lt;/p&gt;

&lt;h1 id=&quot;understanding-different-trend-implementations&quot;&gt;Understanding Different Trend Implementations&lt;/h1&gt;

&lt;p&gt;The beauty of the researchers’ findings is that this relationship holds true across various trend implementations. Whether using exponential moving averages (EMAs), position capping, or different signal processing methods, the core mathematical relationship remains.&lt;/p&gt;

&lt;p&gt;For example, using a classic EMA-based trend strategy where:&lt;/p&gt;

\[\Pi_t := \frac{\lambda_{\tau} L_{\tau}[R_t]}{\sigma_t}\]

&lt;p&gt;Where \(L_{\tau}\) represents an EMA with timescale \(\tau\) and \(R_t\) are the returns normalized by volatility. The performance still captures the spread between long-term and short-term volatility:&lt;/p&gt;

\[L_{\tau &apos;} [G_t] = \frac{\lambda \tau}{\tau -1} \left( \tau L^2_{\tau} [R_t] - L_{\tau &apos;} [R_t^2] \right)\]

&lt;p&gt;When I first implemented trend strategies in my portfolio, I spent endless hours optimizing parameters without fully understanding these mathematical foundations. Knowing the underlying mechanics now helps me focus on what matters - ensuring my trend system captures the right time horizon for the risks I’m trying to hedge.&lt;/p&gt;

&lt;h1 id=&quot;time-horizons-the-critical-factor&quot;&gt;Time Horizons: The Critical Factor&lt;/h1&gt;

&lt;p&gt;One crucial insight that changed my approach to trend following is understanding the importance of time horizons. A trend strategy with a 6-month lookback window provides protection against large market moves that unfold over several months—not against overnight crashes or flash crashes.&lt;/p&gt;

&lt;p&gt;The paper elaborates on this by showing how the strategy’s convexity is most visible when performance is measured over the appropriate timeframe. Using a 180-day trend filter, the researchers demonstrated that aggregating performance over approximately 90 days reveals much stronger convexity than what appears in daily or monthly returns.&lt;/p&gt;

&lt;p&gt;This explains why many investors miss the protective benefits of trend following—they’re looking at returns on the wrong timeframe. During the COVID crash, for instance, many trend followers initially lost money in the sudden selloff, only to recover and profit as the trend established itself over subsequent weeks.&lt;/p&gt;

&lt;h1 id=&quot;real-world-applications-cta-performance&quot;&gt;Real-World Applications: CTA Performance&lt;/h1&gt;

&lt;p&gt;Commodity Trading Advisors (CTAs) are the most prominent practitioners of trend following strategies. The authors analyzed the SG CTA Index, demonstrating that their simple trend model achieved over 80% correlation with the index by using just a handful of liquid futures markets and a basic trend signal.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/sg_cta_replication.png&quot; alt=&quot;SG CTA Index Replication&quot; /&gt;
&lt;em&gt;SG CTA index replication through simple trend model&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What struck me most was how they revealed the convexity of CTA performance. By appropriately measuring over the right timeframe (approximately 6 months for the trend and 3 months for performance aggregation), they showed much stronger convexity than previously observed. The R-squared of the quadratic fit increased from a mere 0.02 in naïve analysis to a more convincing 0.2 using their methodology.&lt;/p&gt;

&lt;h1 id=&quot;diversification-effects-single-asset-vs-multi-asset-trend&quot;&gt;Diversification Effects: Single-Asset vs Multi-Asset Trend&lt;/h1&gt;

&lt;p&gt;The research also revealed an important nuance—diversification reduces convexity. A single-asset trend following strategy shows stronger convexity than a diversified portfolio of trend strategies.&lt;/p&gt;

&lt;p&gt;However, diversified trend strategies still offer significant protection to diversified long portfolios. The authors demonstrated a mathematical relationship showing that trend strategies provide effective hedging for Risk Parity portfolios in particular. This makes intuitive sense to me, as Risk Parity strategies already balance risk across asset classes, and trend strategies can adapt to trends in any of those same asset classes.&lt;/p&gt;

&lt;p&gt;In my experience, this creates a natural complementarity. When rising interest rates hurt both stocks and bonds in 2022, for instance, trend strategies were able to capture the downtrends across multiple assets, providing valuable protection to traditional portfolios.&lt;/p&gt;

&lt;h1 id=&quot;trend-following-vs-options-a-cost-effective-alternative&quot;&gt;Trend Following vs. Options: A Cost-Effective Alternative&lt;/h1&gt;

&lt;p&gt;Many investors turn to options for portfolio protection. While buying index puts provides guaranteed protection, they typically come with a high price tag that erodes long-term returns.&lt;/p&gt;

&lt;p&gt;The research highlights how trend following offers similar convexity benefits but at a lower cost. Their analysis showed that a portfolio of strangle options provides exposure to long-term variance similar to trend following strategies. The key difference? Options have a fixed entry cost (the premium), while trend strategies pay with realized short-term volatility.&lt;/p&gt;

&lt;p&gt;The researchers demonstrate this with a fascinating relationship. A properly constructed strangle portfolio’s P&amp;amp;L can be expressed as:&lt;/p&gt;

\[G_{T}^{\text{strangles}} := \frac{1}{2} \left( S_{T} - S_0 \right)^2 - T \bar{\sigma}^2_{0,T}\]

&lt;p&gt;where \(\bar{\sigma}^2_{0,T}\) is an effective implied volatility. Compare this to the trend following P&amp;amp;L:&lt;/p&gt;

\[G_T := \frac{\lambda}{2} \left( S_{T} - S_0 \right)^2 - \frac{\lambda}{2} \sum_{t=1}^{T} D_t^2\]

&lt;p&gt;Both strategies provide exposure to \((S_T - S_0)^2\) (long-term variance), but at different costs. Since options are typically sold at a premium, trend following offers a more economical approach to convexity over time.&lt;/p&gt;

&lt;p&gt;This makes trend following a more cost-effective hedge over the long run, as demonstrated by their positive long-term performance compared to consistently losing money with long-option portfolios.&lt;/p&gt;

&lt;h1 id=&quot;practical-implementation-considerations&quot;&gt;Practical Implementation Considerations&lt;/h1&gt;

&lt;p&gt;If you’re considering adding trend following to your portfolio, here are some practical considerations I’ve learned through experience:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Time horizon matching&lt;/strong&gt;: Choose trend parameters that align with the market risks you’re trying to hedge. Short-term traders need faster signals, while long-term investors can use longer lookback periods.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Position sizing&lt;/strong&gt;: Proper risk scaling is essential. Too little exposure won’t provide meaningful protection, while too much introduces its own risks.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multiple timeframes&lt;/strong&gt;: Consider using trend signals across multiple timeframes to capture different market regimes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction costs&lt;/strong&gt;: Factor in trading costs, which can significantly impact performance, especially for shorter-term implementations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tax efficiency&lt;/strong&gt;: In taxable accounts, trend strategies may generate more frequent trading and short-term capital gains.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;my-key-takeaways&quot;&gt;My Key Takeaways&lt;/h1&gt;
&lt;p&gt;After studying this paper and implementing trend strategies in my own portfolio, I’ve drawn three important conclusions for investors:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Time horizon matters&lt;/strong&gt;: Trend strategies protect against large moves over their specific time horizon. A 6-month trend strategy won’t help with overnight crashes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diversification reduces convexity&lt;/strong&gt;: Single-asset trend strategies show stronger convexity than diversified ones, but diversification brings other benefits like smoother returns.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Risk parity complement&lt;/strong&gt;: Trend following strategies offer excellent protection for risk parity portfolios, making them valuable for investors with diversified long positions across equities and bonds.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h1&gt;
&lt;p&gt;What fascinated me most about this research is how it quantifies what many trend followers have intuitively understood. These strategies offer affordable downside protection without sacrificing long-term returns, making them uniquely valuable in an investment landscape dominated by high correlation during crises.&lt;/p&gt;

&lt;p&gt;The elegant mathematics behind trend following—swapping short-term variance for long-term variance—explains why these strategies have persisted as effective tools for centuries despite being well-known market anomalies.&lt;/p&gt;

&lt;p&gt;For long-term investors, adding a trend component to your portfolio might be worth considering—especially if you’re concerned about preserving capital during extended market downturns. Whether implementing a simple moving average crossover system or a more sophisticated ensemble approach, the core mathematical benefits remain.&lt;/p&gt;

&lt;p&gt;As markets continue to evolve, trend following strategies offer a robust approach to protection that doesn’t rely on forecasting or timing market tops—just systematically adapting to changing conditions as they unfold.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Have you incorporated trend following strategies in your portfolio? Share your experience in the comments below. What timeframes have you found most effective for your investment goals?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; trend following strategies, portfolio protection, market volatility, CTA performance, risk management, convexity, long-term investing, tail risk, risk parity, options alternatives&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Mar 2025 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/trend-following/</link>
        <guid isPermaLink="true">http://localhost:4000/trend-following/</guid>
        
        <category>trend following</category>
        
        <category>CTA performance</category>
        
        <category>market volatility</category>
        
        <category>convexity</category>
        
        <category>portfolio protection</category>
        
        <category>tail risk</category>
        
        <category>risk parity</category>
        
        <category>options alternatives</category>
        
        <category>hedge funds</category>
        
        
        <category>investing portfolio management</category>
        
        <category>trading strategies</category>
        
        <category>risk management</category>
        
      </item>
    
      <item>
        <title>Unlocking Creativity: My Journey into DALL-E 2 &amp; Diffusion Models</title>
        <description>&lt;h1 id=&quot;unlocking-creativity-my-journey-into-dall-e-2--diffusion-models&quot;&gt;Unlocking Creativity: My Journey into DALL-E 2 &amp;amp; Diffusion Models&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Last updated: March 2025 - Comprehensive guide to understanding the math, applications, and future of diffusion models&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The first time I saw DALL-E 2 generate an “astronaut riding a horse on Mars in watercolor style,” I was speechless. How could a machine create something so imaginative yet so coherent? This question led me down a fascinating rabbit hole into the world of diffusion models – the technology powering today’s most impressive AI art generators like DALL-E 2, Midjourney, and Stable Diffusion.&lt;/p&gt;

&lt;p&gt;In this comprehensive guide, I’m sharing what I’ve learned about these remarkable models, breaking down complex concepts into understandable pieces. Whether you’re a fellow AI enthusiast, a curious artist, or just someone intrigued by the latest tech, I hope you’ll find this journey as fascinating as I did.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#the-magic-behind-the-curtain-understanding-diffusion-models&quot;&gt;The Magic Behind the Curtain: Understanding Diffusion Models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#the-brain-of-the-operation-u-net-architecture&quot;&gt;The Brain of the Operation: U-Net Architecture&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#diffusion-models-in-the-wild-real-world-applications&quot;&gt;Diffusion Models in the Wild: Real-World Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#the-journey-ahead-future-directions-for-diffusion-models&quot;&gt;The Journey Ahead: Future Directions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion-why-diffusion-models-matter&quot;&gt;Conclusion: Why Diffusion Models Matter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references-and-further-reading&quot;&gt;References and Further Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-magic-behind-the-curtain-understanding-diffusion-models&quot;&gt;The Magic Behind the Curtain: Understanding Diffusion Models&lt;/h2&gt;

&lt;p&gt;When I first encountered diffusion models, I was already familiar with GANs (Generative Adversarial Networks) and VAEs (Variational Autoencoders). But diffusion models felt different – more methodical, more intuitive in some ways, despite their mathematical complexity.&lt;/p&gt;

&lt;h3 id=&quot;from-chaos-to-creation-how-diffusion-models-work&quot;&gt;From Chaos to Creation: How Diffusion Models Work&lt;/h3&gt;

&lt;p&gt;The genius of diffusion models lies in their approach to generation: they learn to create by learning to destroy – and then reversing that process. Let me walk you through this counterintuitive but brilliant concept.&lt;/p&gt;

&lt;h4 id=&quot;step-1-forward-diffusion---the-art-of-adding-noise&quot;&gt;Step 1: Forward Diffusion - The Art of Adding Noise&lt;/h4&gt;

&lt;p&gt;Imagine you have a beautiful photograph. Now picture gradually adding static to it, like tuning an old TV set away from its channel. At first, the image gets slightly grainy. Then details start to blur. Eventually, after many steps of adding noise, your photograph becomes unrecognizable static – pure random noise.&lt;/p&gt;

&lt;p&gt;This process is what researchers call “forward diffusion.” Mathematically, at each step, we add a carefully controlled amount of Gaussian noise according to:&lt;/p&gt;

\[\mathbf{x}_t = \sqrt{1-\beta_t}\mathbf{x}_{t-1}+\sqrt{\beta_t}\epsilon\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{x}_t\) is our image at step $t$&lt;/li&gt;
  &lt;li&gt;\(\beta_t\) controls how much noise we add at this step&lt;/li&gt;
  &lt;li&gt;\(\epsilon\) is random noise drawn from a normal distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In probability terms, we’re sampling from this distribution:&lt;/p&gt;

\[q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})\]

&lt;p&gt;After hundreds or thousands of tiny steps, our pristine image becomes pure noise. The interesting part? This destruction follows precise mathematical rules.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/noisy_person.jpg&quot; alt=&quot;A person gradually dissolving into noise&quot; /&gt;
&lt;em&gt;The forward diffusion process gradually transforms a clear image into pure noise through many small steps.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;step-2-reverse-diffusion---the-art-of-creation&quot;&gt;Step 2: Reverse Diffusion - The Art of Creation&lt;/h4&gt;

&lt;p&gt;Now comes the truly magical part. What if we could learn to reverse this process? What if, starting with pure noise, we could gradually remove just the right amount of noise at each step to eventually arrive at a coherent image?&lt;/p&gt;

&lt;p&gt;This is exactly what diffusion models learn to do. They start with random noise and incrementally denoise it, guided by what they’ve learned about the structure of real images.&lt;/p&gt;

&lt;p&gt;The reverse process follows this distribution:&lt;/p&gt;

\[p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_{\theta}(\mathbf{x}_t, t), \Sigma_{\theta}(\mathbf{x}_t, t))\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mu_{\theta}\) is our model’s prediction of the mean (the noise-free direction)&lt;/li&gt;
  &lt;li&gt;\(\Sigma_{\theta}\) is the variance (how confident the model is)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In practice, researchers found that the key challenge is having the model predict the noise that was added at each step. A neural network learns to estimate this noise, and we use that estimation to gradually clean up our image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/flower_diffusion.jpg&quot; alt=&quot;A flower emerging from noise&quot; /&gt;
&lt;em&gt;Reverse diffusion: starting from random noise (left), the model gradually refines the image until a recognizable flower emerges (right).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When I first implemented this on a simple dataset, watching images emerge from random noise felt like witnessing a magic trick whose secrets I finally understood. It’s like seeing a photograph develop in a darkroom, but the process is guided by an AI that’s learned the patterns of our visual world.&lt;/p&gt;

&lt;h4 id=&quot;the-training-process-teaching-ai-to-reverse-time&quot;&gt;The Training Process: Teaching AI to Reverse Time&lt;/h4&gt;

&lt;p&gt;Training a diffusion model requires teaching it to predict the noise added during the forward process. The objective function (what the model tries to optimize) looks complex, but essentially boils down to:&lt;/p&gt;

\[L_{\text{simple}} = \mathbb{E}_{\mathbf{x}_{0}, \epsilon_t} [||\epsilon_t - \epsilon_{\theta}(\mathbf{x}_{t}, t)||^2]\]

&lt;p&gt;This means: “Make your prediction of the noise (\(\epsilon_{\theta}\)) as close as possible to the actual noise (\(\epsilon_t\)) we added.”&lt;/p&gt;

&lt;p&gt;What fascinated me was how this simple objective leads to such powerful generative capabilities. The model learns not just to denoise, but to understand the underlying structure of the data – be it faces, landscapes, or abstract concepts.&lt;/p&gt;

&lt;h2 id=&quot;the-brain-of-the-operation-u-net-architecture&quot;&gt;The Brain of the Operation: U-Net Architecture&lt;/h2&gt;

&lt;p&gt;When discussing diffusion models, we can’t skip over the neural network architecture that makes it all possible. Most diffusion models use a modified U-Net, which was originally developed for biomedical image segmentation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/unet.png&quot; alt=&quot;U-Net Architecture&quot; /&gt;
&lt;em&gt;The U-Net architecture features a symmetric encoder-decoder structure with skip connections that help preserve spatial information.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The U-Net’s design is particularly clever for diffusion models because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Its encoder path&lt;/strong&gt; compresses the image to capture high-level concepts and relationships&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Its decoder path&lt;/strong&gt; expands back to full resolution for detailed generation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Skip connections&lt;/strong&gt; between corresponding encoder and decoder layers preserve fine details that might otherwise be lost during compression&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I like to think of it as having both a “big picture” understanding and an attention to detail – exactly what you need when reconstructing complex images from noise.&lt;/p&gt;

&lt;p&gt;In my experiments, I found that these skip connections are crucial. Without them, the model struggles to generate coherent, detailed images. It’s like trying to describe a painting you saw once versus having reference notes to consult as you describe it.&lt;/p&gt;

&lt;h2 id=&quot;diffusion-models-in-the-wild-real-world-applications&quot;&gt;Diffusion Models in the Wild: Real-World Applications&lt;/h2&gt;

&lt;p&gt;The theory behind diffusion models is fascinating, but what truly excites me is seeing how they’re transforming various fields:&lt;/p&gt;

&lt;h3 id=&quot;1-text-to-image-generation-dall-e-2-imagen-and-beyond&quot;&gt;1. Text-to-Image Generation: DALL-E 2, Imagen, and Beyond&lt;/h3&gt;

&lt;p&gt;OpenAI’s DALL-E 2 and Google’s Imagen represent some of the most impressive applications of diffusion models. These systems can generate stunningly realistic images from text descriptions, opening new creative possibilities for artists, designers, and storytellers.&lt;/p&gt;

&lt;p&gt;What makes these systems particularly impressive is their understanding of composition, style, and even abstract concepts. When I first typed “a teddy bear fixing a car on the moon” into DALL-E 2, I was amazed at how it captured not just the objects but also lighting conditions, perspective, and the whimsical nature of the prompt.&lt;/p&gt;

&lt;h3 id=&quot;2-beyond-images-audio-video-and-time-series-data&quot;&gt;2. Beyond Images: Audio, Video, and Time Series Data&lt;/h3&gt;

&lt;p&gt;While images get most of the attention, diffusion models are proving effective for other data types too:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Audio generation&lt;/strong&gt;: Creating realistic speech, music, and sound effects&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Video synthesis&lt;/strong&gt;: Generating coherent video sequences frame by frame&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time series forecasting&lt;/strong&gt;: Predicting weather patterns, stock prices, and other sequential data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The same principles that allow diffusion models to understand the structure of images apply to these other domains – it’s about learning the patterns and relationships within the data.&lt;/p&gt;

&lt;h3 id=&quot;3-scientific-applications-molecular-design-and-beyond&quot;&gt;3. Scientific Applications: Molecular Design and Beyond&lt;/h3&gt;

&lt;p&gt;Perhaps the most surprising application I’ve encountered is in molecular design for drug discovery. Traditional approaches to designing new molecules often rely on rules-based systems or more rigid generative methods.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/molecules_diffusion_models.png&quot; alt=&quot;Molecule generation with diffusion models&quot; /&gt;
&lt;em&gt;Diffusion models can generate valid molecular structures by learning the patterns of existing molecules and gradually refining random noise into coherent chemical structures.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Diffusion models approach this differently – they learn the underlying distribution of valid molecular structures and can generate novel molecules that satisfy specific criteria. This is groundbreaking because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They don’t assume atoms are independent (they model the entire structure)&lt;/li&gt;
  &lt;li&gt;They don’t require arbitrary atom ordering like some other methods&lt;/li&gt;
  &lt;li&gt;The gradual, iterative nature allows for more controlled generation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The papers by &lt;a href=&quot;https://arxiv.org/pdf/2203.17003&quot;&gt;Hoogeboom et al. (2022)&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/2210.13695&quot;&gt;Schneuing et al. (2023)&lt;/a&gt; demonstrate how these models can revolutionize computational chemistry and drug discovery.&lt;/p&gt;

&lt;h3 id=&quot;4-medical-imaging-and-healthcare-applications&quot;&gt;4. Medical Imaging and Healthcare Applications&lt;/h3&gt;

&lt;p&gt;An application area of diffusion models that genuinely excites me is their impact on healthcare, particularly in medical imaging. The precise, controlled generation capabilities of these models are proving remarkably valuable in a field where accuracy and detail can literally save lives.&lt;/p&gt;

&lt;p&gt;Here are some transformative applications I’ve been following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Medical Image Enhancement&lt;/strong&gt;: Diffusion models can transform low-resolution or noisy medical scans (MRI, CT, X-ray) into sharper, clearer images without requiring additional radiation exposure for patients. In a recent project, I saw how a diffusion model could enhance subtle details in mammography images that might otherwise be missed.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Synthetic Data Generation&lt;/strong&gt;: One of healthcare’s biggest challenges is limited data availability due to privacy concerns and rare conditions. Diffusion models can generate realistic, diverse synthetic medical images to augment training datasets, helping improve diagnostic algorithms without compromising patient privacy.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Anomaly Detection&lt;/strong&gt;: By learning the distribution of healthy tissue appearances, diffusion models can identify deviations that might indicate disease. What’s fascinating is how they can detect subtle patterns that even experienced radiologists might overlook.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cross-Modality Translation&lt;/strong&gt;: Converting between imaging modalities (e.g., MRI to CT) allows physicians to leverage information from multiple sources without subjecting patients to additional scans. I was particularly impressed by recent research showing how diffusion models can generate synthetic CT scans from MRI data with remarkable accuracy.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ensemble_diffusion.jpg&quot; alt=&quot;Medical imaging applications&quot; /&gt;
&lt;em&gt;Diffusion models can enhance medical images, generate synthetic training data, and help identify anomalies that might indicate disease.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What makes diffusion models particularly suitable for these applications is their probabilistic nature and ability to capture fine details while maintaining global coherence. Unlike traditional image processing techniques that might smooth out important details, diffusion models preserve the subtle variations that can be clinically significant.&lt;/p&gt;

&lt;p&gt;Researchers at several medical institutions are now exploring how these models can be integrated into clinical workflows, potentially improving diagnostic accuracy while reducing costs and patient discomfort. The potential impact on early disease detection and treatment planning is enormous.&lt;/p&gt;

&lt;h2 id=&quot;the-journey-ahead-future-directions-for-diffusion-models&quot;&gt;The Journey Ahead: Future Directions for Diffusion Models&lt;/h2&gt;

&lt;p&gt;As exciting as current diffusion models are, I believe we’re just scratching the surface of their potential. Here are some developments I’m watching closely:&lt;/p&gt;

&lt;h3 id=&quot;1-efficiency-improvements&quot;&gt;1. Efficiency Improvements&lt;/h3&gt;

&lt;p&gt;Current diffusion models require many steps to generate high-quality samples, making them computationally expensive. Techniques like distillation and improved sampling methods (like DDIM - Denoising Diffusion Implicit Models) are already making significant strides in reducing this computational burden.&lt;/p&gt;

&lt;p&gt;When I first ran a diffusion model on my own hardware, it took nearly a minute to generate a single image. Newer approaches can do this in seconds or less, making real-time applications increasingly feasible.&lt;/p&gt;

&lt;h3 id=&quot;2-controllable-generation&quot;&gt;2. Controllable Generation&lt;/h3&gt;

&lt;p&gt;The ability to guide the generation process with more specific controls is an exciting frontier. Imagine being able to specify exactly where objects should appear in an image, or precisely controlling the style and composition.&lt;/p&gt;

&lt;p&gt;Classifier guidance and conditioning mechanisms are making this increasingly possible, opening doors for more precise creative applications.&lt;/p&gt;

&lt;h3 id=&quot;3-cross-domain-applications&quot;&gt;3. Cross-Domain Applications&lt;/h3&gt;

&lt;p&gt;What happens when we apply diffusion models across different domains simultaneously? Could we generate coordinated music and visuals? Or perhaps molecules with specific properties that also map to specific protein interactions?&lt;/p&gt;

&lt;p&gt;The potential for cross-domain applications feels limitless and represents one of the most exciting research directions.&lt;/p&gt;

&lt;h2 id=&quot;conclusion-why-diffusion-models-matter&quot;&gt;Conclusion: Why Diffusion Models Matter&lt;/h2&gt;

&lt;p&gt;Diffusion models represent one of those rare algorithmic breakthroughs that fundamentally change what’s possible in AI. Their principled approach to generation – gradually crafting structure from noise – offers both theoretical elegance and practical power.&lt;/p&gt;

&lt;p&gt;What I find most compelling about these models is how they mirror creative processes in nature and human art. Creation often involves iteration – starting with rough outlines and gradually refining details. Diffusion models formalize this intuitive process within a mathematical framework.&lt;/p&gt;

&lt;p&gt;Whether you’re a researcher pushing the boundaries of these techniques, a developer implementing them in applications, or simply someone fascinated by AI’s creative potential, diffusion models offer something to marvel at. They remind us that sometimes the most impressive breakthroughs come not from completely new ideas, but from rethinking and formalizing processes we already intuitively understand.&lt;/p&gt;

&lt;p&gt;As I continue exploring this field, I’m constantly amazed by how quickly it’s evolving. The papers I read today build on work published just months ago, and the applications seem to multiply weekly. It’s a thrilling time to be involved in this area, and I can’t wait to see where diffusion models take us next.&lt;/p&gt;

&lt;p&gt;What applications of diffusion models are you most excited about? I’d love to hear your thoughts in the comments!&lt;/p&gt;

&lt;h2 id=&quot;frequently-asked-questions-about-diffusion-models&quot;&gt;Frequently Asked Questions About Diffusion Models&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Q: How do diffusion models compare to GANs for image generation?&lt;/strong&gt;&lt;br /&gt;
A: While GANs (Generative Adversarial Networks) are faster at generation time, diffusion models typically produce higher quality and more diverse images. Diffusion models are also generally more stable during training and don’t suffer from problems like mode collapse that can plague GANs. According to the Dhariwal &amp;amp; Nichol study (2021), diffusion models outperform GANs on image synthesis benchmarks when properly optimized.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q: How long does it take to generate an image with a diffusion model?&lt;/strong&gt;&lt;br /&gt;
A: Traditional diffusion models can take hundreds of steps to generate a high-quality image, which might require several seconds to minutes depending on the hardware. However, recent advancements like DDIM (Denoising Diffusion Implicit Models) and distillation techniques have significantly reduced generation time, with some models able to generate images in just a few seconds or even real-time on powerful GPUs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q: What hardware do I need to run diffusion models?&lt;/strong&gt;&lt;br /&gt;
A: For inference (generating images), consumer-grade GPUs with 8+ GB of VRAM can run optimized models like Stable Diffusion. For training, enterprise-grade GPUs or TPUs are typically required due to the computational demands. Cloud services like Google Colab, Kaggle, or specialized AI platforms offer accessible ways to experiment with these models.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q: Are there ethical concerns with diffusion models?&lt;/strong&gt;&lt;br /&gt;
A: Yes, several ethical considerations exist including: potential for generating misleading deepfakes, copyright concerns regarding training data and generated content, potential biases in the generated outputs, and environmental impact due to computational requirements. Researchers and companies are actively working on addressing these issues through improved model design, responsible use policies, and transparency efforts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q: How can I learn to implement diffusion models?&lt;/strong&gt;&lt;br /&gt;
A: Start with understanding the basics of deep learning and generative models. Then explore libraries like Hugging Face’s Diffusers, which provide pre-implemented models and pipelines. For a deeper understanding, study the papers referenced in this article and try implementing simplified versions. Online courses and tutorials specifically focused on generative AI are increasingly available as well.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references-and-further-reading&quot;&gt;References and Further Reading&lt;/h2&gt;

&lt;p&gt;If you’re interested in diving deeper into diffusion models, here are some resources I’ve found particularly valuable:&lt;/p&gt;

&lt;h3 id=&quot;foundational-papers&quot;&gt;Foundational Papers&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Ho, J., Jain, A., &amp;amp; Abbeel, P. (2020). &lt;a href=&quot;https://arxiv.org/abs/2006.11239&quot;&gt;Denoising Diffusion Probabilistic Models&lt;/a&gt;. In &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; (NeurIPS 2020). The foundational paper that kickstarted the current wave of diffusion model research.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., &amp;amp; Ganguli, S. (2015). &lt;a href=&quot;https://arxiv.org/abs/1503.03585&quot;&gt;Deep Unsupervised Learning using Nonequilibrium Thermodynamics&lt;/a&gt;. In &lt;em&gt;Proceedings of the 32nd International Conference on Machine Learning&lt;/em&gt; (ICML 2015). The original paper introducing the diffusion model concept.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Song, Y., &amp;amp; Ermon, S. (2019). &lt;a href=&quot;https://arxiv.org/abs/1907.05600&quot;&gt;Generative Modeling by Estimating Gradients of the Data Distribution&lt;/a&gt;. In &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; (NeurIPS 2019). Introduced score-based generative models, closely related to diffusion models.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-and-improvements&quot;&gt;Applications and Improvements&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Dhariwal, P., &amp;amp; Nichol, A. (2021). &lt;a href=&quot;https://arxiv.org/abs/2105.05233&quot;&gt;Diffusion Models Beat GANs on Image Synthesis&lt;/a&gt;. In &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; (NeurIPS 2021). A comprehensive comparison showing how diffusion models outperform GANs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rombach, R., Blattmann, A., Lorenz, D., Esser, P., &amp;amp; Ommer, B. (2022). &lt;a href=&quot;https://arxiv.org/abs/2112.10752&quot;&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/a&gt;. In &lt;em&gt;Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition&lt;/em&gt; (CVPR 2022). Introduces Stable Diffusion, solving computational efficiency issues.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nichol, A., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B., Sutskever, I., &amp;amp; Chen, M. (2021). &lt;a href=&quot;https://arxiv.org/abs/2112.10741&quot;&gt;GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models&lt;/a&gt;. A text-to-image diffusion model from OpenAI.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., … &amp;amp; Norouzi, M. (2022). &lt;a href=&quot;https://arxiv.org/abs/2205.11487&quot;&gt;Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding&lt;/a&gt;. Introduces Google’s Imagen text-to-image model.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;medical-applications&quot;&gt;Medical Applications&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Ozbey, M., Dalmaz, O., Dar, S. U., Bedel, H. A., Özturk, Ş., Güngör, A., &amp;amp; Çukur, T. (2023). &lt;a href=&quot;https://arxiv.org/abs/2207.08208&quot;&gt;Unsupervised Medical Image Translation with Adversarial Diffusion Models&lt;/a&gt;. Explores cross-modality translation in medical imaging.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pinaya, W. H., Tudosiu, P. D., Valindria, V., Thomas, R., Dafflon, J., Meyer, M. I., … &amp;amp; Cardoso, M. J. (2023). &lt;a href=&quot;https://arxiv.org/abs/2209.07162&quot;&gt;Brain Imaging Generation with Latent Diffusion Models&lt;/a&gt;. &lt;em&gt;Medical Image Analysis&lt;/em&gt;, 84, 102704. Application of diffusion models to brain MRI generation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;molecular-design&quot;&gt;Molecular Design&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Hoogeboom, E., Satorras, V. G., Vignac, C., &amp;amp; Welling, M. (2022). &lt;a href=&quot;https://arxiv.org/abs/2203.17003&quot;&gt;Equivariant Diffusion for Molecule Generation in 3D&lt;/a&gt;. In &lt;em&gt;Proceedings of the 39th International Conference on Machine Learning&lt;/em&gt; (ICML 2022).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Schneuing, A., Du, Y., Harris, C., Jamasb, A., Igashov, I., Zhu, W., … &amp;amp; Welling, M. (2023). &lt;a href=&quot;https://arxiv.org/abs/2210.13695&quot;&gt;Structure-based Drug Design with Equivariant Diffusion Models&lt;/a&gt;. Applying diffusion models to drug discovery.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tools-and-libraries&quot;&gt;Tools and Libraries&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://huggingface.co/docs/diffusers/index&quot;&gt;Hugging Face’s Diffusers Library&lt;/a&gt; - An excellent resource for implementing and experimenting with diffusion models without building everything from scratch.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://stability.ai/stable-diffusion&quot;&gt;Stability AI’s Stable Diffusion&lt;/a&gt; - The official repository and documentation for one of the most popular open-source diffusion models.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/diffusers/tree/main/examples/community&quot;&gt;Diffusers Community&lt;/a&gt; - Community examples showing how to implement various diffusion model techniques.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you have any questions about these resources or want to discuss diffusion models further, feel free to reach out in the comments section below. Happy exploring!&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Jan 2024 00:00:00 +0100</pubDate>
        <link>http://localhost:4000/diffusion-models/</link>
        <guid isPermaLink="true">http://localhost:4000/diffusion-models/</guid>
        
        <category>dall-e 2</category>
        
        <category>stable diffusion</category>
        
        <category>image generation</category>
        
        <category>ai art</category>
        
        <category>generative models</category>
        
        <category>text-to-image</category>
        
        <category>medical imaging</category>
        
        <category>molecular design</category>
        
        
        <category>deep learning</category>
        
        <category>artificial intelligence</category>
        
        <category>generative ai</category>
        
        <category>diffusion models</category>
        
      </item>
    
  </channel>
</rss>
