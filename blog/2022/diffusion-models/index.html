<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Fabio  Capela | Diffusion Models</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2022/diffusion-models/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-179028456-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-179028456-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: grey;
  text-align: center;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Diffusion Models",
      "description": "Diffusion models are the new kid in town as to what regards high fidelity image generation. We present the main ideas in this blog post",
      "published": "February 20, 2022",
      "authors": [
        
        {
          "author": "Fabio Capela",
          "authorURL": "",
          "affiliations": [
            {
              "name": "DLab, Firmenich SA",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://capfab.io"><!-- href="http://localhost:4000/"> -->
       <span class="font-weight-bold">Fabio</span>   Capela
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Diffusion Models</h1>
        <p>Diffusion models are the new kid in town as to what regards high fidelity image generation. We present the main ideas in this blog post</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <p>Several models in image synthesis have been studied in the last years. Among the most known models,
we have <em>Variational AutoEncoders</em> (<strong>VAE</strong>), <em>Generative Adversarial Networks</em> (<strong>GAN</strong>) and
<strong>flow-based</strong> models. We might make a deep dive on those models at some point, but in this blog
post we have decided to pay close attention to the last kid in town: diffusion models.</p>

<p>The idea behind diffusion models is pretty intuitive: take an image and add noise (Gaussian noise
preferably) until the image becomes completely blurry (more precisely isotropic Gaussian noise,
i.e. with a covariance matrix represented by $\Sigma = \sigma^2 \mathbb{I}$). Finally, you ask
the model to learn to reverse the process and get back to the initial image. Once the model has trained,
it will be able to generate images from pure random noise. Interestingly, diffusion models, due to
the fact that they add noise to the initial image during training, are always working with latent
variables of the same dimensionality as the original image. Letâ€™s dig into more details.</p>

<h2 id="forward-diffusion-process">Forward diffusion process</h2>

<p>As already said, diffusion models are inherently latent variable models where a data point
\(\mathbf{x}_0 \sim q(\mathbf{x})\) is sampled from a real distribution. Then, Gaussian noise is
added to the data point, based on a scheduled variance \(\beta_1,\cdots,\beta_T\). The
approximate posterior \(q(\mathbf{x}_{1:T} | \mathbf{x}_0 )\) is called a <strong>forward diffusion process</strong>
, corresponding to a fixed Markov chain:</p>

\[q(\mathbf{x}_{1:T}| \mathbf{x}_0)=\prod_{t=1}^T q(\mathbf{x}_t| \mathbf{x}_{t-1}), \qquad q(\mathbf{x}_t| \mathbf{x}_{t-1}) = \mathcal{N}(\sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})\]

<p>As a consequence, the typical features of $\mathbf{x}_0$ are lost as $t$ becomes larger.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/img_forward_process1.png" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    This image shows the Markov chain of the forward diffusion process that slowly transforms
    the image of a cat to a noisy image through addition of Gaussian noise.
</div>

<p>Whatâ€™s nice about the diffusion forward process is that we can sample any latent
variable $\mathbf{x}_t$ at any arbitrary time $t$ by using the reparametrization trick:</p>

\[\begin{align*}
\mathbf{x}_t &amp;= \mu(\mathbf{x}_{t-1}) + \Sigma_t \cdot\mathbf{z}_{t-1}, \quad \text{where} \quad \mathbf{z}_{t-1} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \\
&amp;= \sqrt{1-\beta_t} \mathbf{x}_{t-1} +\sqrt{\beta_t}\mathbf{z}_{t-1} \\
&amp;= \sqrt{\alpha_t} \mathbf{x}_{t-1} + \sqrt{1-\alpha_t}\mathbf{z}_{t-1}, \quad \text{with} \quad \alpha_t \equiv 1-\beta_t\\
&amp;= \cdots \\
&amp;= \sqrt{\bar{\alpha}_t} \mathbf{x}_{0} + \sqrt{1-\bar{\alpha}_t}\mathbf{z}_{0}, \quad \text{where} \quad \bar{\alpha}_t \equiv \prod_{t=1}^T \alpha_i
\end{align*}\]

<p>To be able to fully rederive the previous result one has to remember that if
\(\mathbf{l}_{t-1}\sim \mathcal{N}(\mathbf{0},\sigma_{t-1}^2\mathbf{I})\) and
\(\mathbf{l}_{t-2}\sim \mathcal{N}(\mathbf{0},\sigma_{t-2}^2 \mathbf{I})\), then the distribution which
merges the two previous distributions is given by
\(\bar{\mathbf{l}}_{t-2} \sim \mathcal{N}(\mathbf{0}, (\sigma_{t-1}^2+\sigma_{t-2}^2)\mathbf{I})\).</p>

<h2 id="reverse-time-generative-process">Reverse time generative process</h2>

<p>A more interesting process would be a reverse process \(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)
that would allow to generate an approximate sample \(q(\mathbf{x}_0)\) from a Gaussian noise
input \(\mathbf{x}_T \sim \mathcal{N}(\mathbf{0},\mathbf{I})\). However, it turns out
that \(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\) is not easily obtained, as we do need the full dataset.
That is why an approximate process \(p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_t)\) needs to be
learned using a neural network. In <d-cite key="Jasch2015"></d-cite>, they note that
\(q(\mathbf{x}_{t-1}| \mathbf{x}_t)\) approaches a <em>diagonal</em> Gaussian distribution
as \(T\rightarrow \infty\) and correspondingly \(\beta_t \rightarrow 0\). As a consequence, we can define :</p>

\[p_{\theta}(\mathbf{x}_{0:T})\equiv p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t), \qquad p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{\mu}_\theta(\mathbf{x}_t,t),\mathbf{\Sigma}_\theta(\mathbf{x}_t,t))\]

<p>It is therefore a Markov chain with a learned Gaussian transition. The mean \(\mathbf{\mu}_{\theta}\)
and the diagonal covariance \(\mathbf{\Sigma}_{\theta}\) share the same parameters \(\theta\).
It is to be noted that both \(\mathbf{\mu}_{\theta}\) and \(\mathbf{\Sigma}_{\theta}\) take two
inputs: a diffusion step \(t \in \mathbb{N}\) and a variable \(\mathbf{x}_t \in \mathbb{R}^{L}\).
\(\mathbf{\mu}_{\theta}\) outputs an $L$-dimensional vector as the mean, and \(\mathbf{\Sigma}_{\theta}\)
outputs a real number.</p>

<p>Even though \(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\) is difficult to obtain, it is tractable to
obtain \(q(\mathbf{x}_{t-1}| \mathbf{x}_t, \mathbf{x}_0)\), conditioned on \(\mathbf{x}_0\), by using
Bayes theorem:</p>

\[\begin{align*}
q(\mathbf{x}_{t-1}| \mathbf{x}_t, \mathbf{x}_0) &amp;= \frac{q(\mathbf{x}_t| \mathbf{x}_{t-1}, \mathbf{x}_0)   q(\mathbf{x}_{t-1}| \mathbf{x}_0)}{q(\mathbf{x}_t | \mathbf{x}_0)} \\
&amp;= \frac{\mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I}) \mathcal{N}(\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0,(1-\bar{\alpha}_{t-1})\mathbf{I})}{\mathcal{N}\left(\sqrt{\bar{\alpha}_t}\mathbf{x}_0),(1-\bar{\alpha}_t)\mathbf{I} \right)} \\
&amp;\propto \exp\left(-\frac{1}{2}\left\{\left(\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) \mathbf{x}^2_{t-1}-\left(2\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t +2\frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0\right) \mathbf{x}_{t-1}\right\}\right) +\text{C}(\mathbf{x}_t, \mathbf{x}_0)
\end{align*}\]

<p>where \(C(\mathbf{x}_t,\mathbf{x}_0)\) is a function not depending on \(\mathbf{x}_{t-1}\)
and therefore of no interest. As we know well the fractional density dependencies of the
mean and the variance, we are able to identify the following terms:</p>

\[\begin{align*}
\tilde{\mu} &amp;:= \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0 + \frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t \\
\tilde{\beta}_t &amp; := \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t \\
q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)&amp;:=\mathcal{N}(\tilde{\mu}(\mathbf{x}_t,\mathbf{x}_0),\tilde{\beta}\mathbf{I})
\end{align*}\]

<p>As you may have understood, such setup is very close to a VAE and therefore the natural
loss to consider is the variational lower bound to optimize the negative log-likelihood.
It turns out that thanks to the calculation \(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)\)
that we have performed, our lives will be easier for the calculation of the loss.</p>

<h2 id="the-loss">The loss</h2>

<p>First of all, as an exercise, letâ€™s use Jensenâ€™s inequality to get back the 
variational lower bound. To do so, we need to minimize the cross-entropy:</p>

\[\begin{align*}
\text{L}_{\text{CE}} &amp;= -\mathbb{E}_{q(\mathbf{x}_0)} \log p_{\theta}(\mathbf{x}_0) \\
&amp;= -\mathbb{E}_{q(\mathbf{x}_0)} \log \left( \int p_{\theta}(\mathbf{x}_{0:T}) d\mathbf{x}_{1:T} \right) \\
&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log \left(\int q(\mathbf{x}_{1:T}|\mathbf{x}_0) \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}  d\mathbf{x}_{1:T}\right) \\
&amp;=-\mathbb{E}_{q(\mathbf{x}_0)} \log\left( \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}
 \right)
\\
&amp;\leq - \mathbb{E}_{q(\mathbf{x}_{0:T})} \log \left( \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \right) \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \log \left( \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_{\theta}(\mathbf{x}_{0:T})} \right) = \text{L}_{\text{VLB}}
\end{align*}\]

<p>What we need is to transform the above expression into a bunch of terms that are actually
computable. That is explained in detail in the appendix of the article <d-cite key="Jasch2015"></d-cite>
and that we reproduce here. It is to be noted that the calculation that we put here for our own
curiosity is fully reproduced in the excellent blog Â« What are diffusion models? Â» 
by Lilian Weng <d-cite key="weng2021diffusion"></d-cite>. The calculation goes as follows:</p>

\[\begin{aligned}
L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&amp;= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big]\\
&amp;= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\
&amp;= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]
\end{aligned}\]

<p>As such, the VLB loss is a sum of Kullback-Leibler (KL) divergences between
two Gaussian distributions plus the term \(L_0\) that comes directly from the trained
neural network. As such, if we disregard the $L_0$-term, the loss is analytically tractable.
It is to be remarked that $L_T$ is constant because $q$ has no parameters and \(\mathbf{x}_T\)
is a Gaussian noise.</p>

<h2 id="training--sampling">Training &amp; Sampling</h2>

<p>Now that we have the explicit formula for the loss, we can plug the learnable
distribution \(p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{\mu}_\theta(\mathbf{x}_t,t),\mathbf{\Sigma}_\theta(\mathbf{x}_t,t))\)
and the distribution \(q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\mathcal{N}(\tilde{\mu}(\mathbf{x}_t,\mathbf{x}_0),\tilde{\beta}\mathbf{I})\)
into the tractable KL divergence.</p>

<p>As the term \(L_T\) is constant, we donâ€™t need to include it in the loss. Moreover, we
have the term \(L_0\) that should contribute with a constant. However, letâ€™s first focus on
the term $L_{t-1}$, which is the main contributor to the variational lower bound.
Under the assumption that the covariance is the same, i.e. that 
\(\tilde{\beta}=\mathbf{\Sigma}_\theta(\mathbf{x}_t,t)\), then the KL divergence 
is the squared \(l_2\) distance between the respective means of the distributions 
involved in the \(\log\).</p>

<p>To straightforwardly work out the main term of the variational lower bound, we might want 
to rewrite $\mu_{\theta}(\mathbf{x}_t,t)$ by noticing that once we introduce the relation 
$\mathbf{x}_t=\sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\mathbf{z}_t$, 
then the mean $\tilde{\mu}(\mathbf{x}_t,\mathbf{x}_0)$ becomes:</p>

\[\tilde{\mu}(\mathbf{x}_t,\mathbf{z}_t)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\mathbf{z}_t\right).\]

<p>By taking the same parametrization for the mean $\mu_{\theta}(\mathbf{x}_t,t)$, 
we can make the model predict $\mathbf{z}_t$ from the input $\mathbf{x}_t$, through 
the minimization of the KL divergence that takes the form of the following expectation:</p>

\[L_t=\frac{\beta_t}{2\alpha_t(1-\bar{\alpha}_{t-1})}\mathbb{E}_{\mathbf{x}_0,\mathbf{z}}\left[\lVert\mathbf{z}_t-\mathbf{z}_{\theta}(\mathbf{x}_t,t)\rVert^2\right].\]

<p>This is the main loss considered in the different diffusion models in 
literature. In <d-cite key="Ho2020"></d-cite>, the term in front of the expectation is dropped 
as it works practically better for training.</p>

<p>We have now all the ingredients needed for the training and sampling algorithms. 
We can see both the training and sampling algorithms in the following figure.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/DDPM-algo50.png" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    The training and sampling algorithm of a denoising diffusion process model (source image: <d-cite key="Ho2020"></d-cite>)
</div>

<h2 id="conditional-diffusion-models">Conditional diffusion models</h2>

<p>It is trivial to condition the above models to a label associated with an image. Letâ€™s consider the
data \(\mathbf{x}_0\) has an associated label \(\mathbf{c}\), the aim becomes then to learn a
conditional model \(p_{\theta}(\mathbf{x}_0|\mathbf{c})\). To do so, we modify the
diffusion model by including \(\mathbf{c}\) as an input to the reverse process</p>

\[p_{\theta}(\mathbf{x}_{0:T}|\mathbf{c})\equiv p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t,\mathbf{c}), \quad p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{c}) = \mathcal{N}(\mathbf{\mu}_\theta(\mathbf{x}_t,t,\mathbf{c}),\mathbf{\Sigma}_\theta(\mathbf{x}_t,t,\mathbf{c}))\]

\[L_{\theta}(\mathbf{x}_{0:T}\vert\mathbf{c})=\mathbb{E}_q \left[L_T(\mathbf{x}_0) + \sum_{t&gt;1} D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t,\mathbf{c})) - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1,\mathbf{c}) \right]\]

<p>Both the data point and the label are sampled from the same data distribution \(q(\mathbf{x}_0,\mathbf{c})\).
What needs to be considered is the injection of $\mathbf{c}$ as an extra input to the neural
networks \((\mu_{\theta},\Sigma_{\theta})\). Different sorts of strategies do exist in the literature
about the best architectures to do so. The model in <d-cite key="Ho2020"></d-cite> uses U-nets with some concatenation
of the label embeddings in intermediate layers of the network, for example. A label classifier
\(f_{\phi}(\mathbf{c}\vert\mathbf{x}_t)\) can also be used to drive the diffusion process
(through gradient descent, i.e. \(\nabla_{\mathbf{x}_t}\log f_{\phi}(\mathbf{c}\vert\mathbf{x}_t))\)
to reach the correct conditioning in image synthesis (see <d-cite key="Nichol2021"></d-cite> for more on this).</p>

<h2 id="conclusion">Conclusion</h2>

<p>Diffusion probabilistic models are a great tool for image synthesis. We have presented the math 
foundations in the present blog, with particular focus on the construction of the loss. Whatâ€™s 
interesting about those models is that they are both analytically tractable and flexible to fit 
complex data structure. Even though diffusion models are considered state-of-the-art in terms of image 
synthesis, they still lack speed in the generation process as they rely on long Markov chain diffusion steps.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &#127279; Copyleft 2022 by Fabio  Capela, but you can use freely.
    
    
    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib">
  </d-bibliography>

</html>
